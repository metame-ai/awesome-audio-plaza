# Audio Language Model

- [Audio Language Model](#audio-language-model) 
  - [Papers](#papers)
  - [Survey](#survey)
  - [Evaluation](#evaluation)
  - [Projects](#projects)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Papers

- **State-Space Large Audio Language Models**, `arXiv, 2411.15685`, [arxiv](http://arxiv.org/abs/2411.15685v1), [pdf](http://arxiv.org/pdf/2411.15685v1.pdf), cication: [**-1**](None) 

	 *Saurabhchand Bhati, Yuan Gong, Leonid Karlinsky, ..., Rogerio Feris, James Glass*
- ðŸŒŸ **Scaling Speech-Text Pre-training with Synthetic Interleaved Data**, `arXiv, 2411.17607`, [arxiv](http://arxiv.org/abs/2411.17607v1), [pdf](http://arxiv.org/pdf/2411.17607v1.pdf), cication: [**-1**](None) 

	 *Aohan Zeng, Zhengxiao Du, Mingdao Liu, ..., Yuxiao Dong, Jie Tang*
- ðŸŒŸ **A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks 
  with Large Language Models**, `arXiv, 2411.08742`, [arxiv](http://arxiv.org/abs/2411.08742v1), [pdf](http://arxiv.org/pdf/2411.08742v1.pdf), cication: [**-1**](None) 

	 *Dingdong Wang, Mingyu Cui, Dongchao Yang, ..., Xueyuan Chen, Helen Meng*
- **Roadmap towards Superhuman Speech Understanding using Large Language 
  Models**, `arXiv, 2410.13268`, [arxiv](http://arxiv.org/abs/2410.13268v1), [pdf](http://arxiv.org/pdf/2410.13268v1.pdf), cication: [**-1**](None)

	 *Fan Bu, Yuhao Zhang, Xidong Wang, ..., Qun Liu, Haizhou Li*

## Survey

- [Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey](https://arxiv.org/abs/2412.06602)
- **Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for 
  Measuring the Capabilities of Spoken Language Models with 180 Tasks**, `arXiv, 2411.05361`, [arxiv](http://arxiv.org/abs/2411.05361v1), [pdf](http://arxiv.org/pdf/2411.05361v1.pdf), cication: [**-1**](None) 

	 *Chien-yu Huang, Wei-Chih Chen, Shu-wen Yang, ..., Shinji Watanabe, Hung-yi Lee*

## Evaluation

- **What Do Speech Foundation Models Not Learn About Speech?**, `arXiv, 2410.12948`, [arxiv](http://arxiv.org/abs/2410.12948v1), [pdf](http://arxiv.org/pdf/2410.12948v1.pdf), cication: [**-1**](None) 

	 *Abdul Waheed, Hanin Atwany, Bhiksha Raj, ..., Rita Singh*
- **Audio Is the Achilles' Heel: Red Teaming Audio Large Multimodal Models**, `arXiv, 2410.23861`, [arxiv](http://arxiv.org/abs/2410.23861v1), [pdf](http://arxiv.org/pdf/2410.23861v1.pdf), cication: [**-1**](None) 

	 *Hao Yang, Lizhen Qu, Ehsan Shareghi, ..., Gholamreza Haffari*
- **MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark**, `arXiv, 2410.19168`, [arxiv](http://arxiv.org/abs/2410.19168v1), [pdf](http://arxiv.org/pdf/2410.19168v1.pdf), cication: [**-1**](None) 

	 *S Sakshi, Utkarsh Tyagi, Sonal Kumar, ..., Sreyan Ghosh, Dinesh Manocha* Â· ([sakshi113.github](https://sakshi113.github.io/mmau_homepage/))

## Projects


## Toolkits


## Misc
## Misc
- [Qwen2-Audio is a SOTA small-scale multimodal model (AudioLM) that handles audio and text inputs, allowing you to have voice interactions without ASR modules](https://huggingface.co/NexaAIDev/Qwen2-Audio-7B-GGUF)  ðŸ¤— 