# Voice Omni

- [Voice Omni](#voice-omni)
  - [Survey](#survey)
  - [Voice Omni](#voice-omni-1)
  - [Duplex](#duplex)
  - [Evaluation](#evaluation)
  - [Projects](#projects)
  - [Products](#products)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Survey

- [A Survey on Speech Large Language Models](https://arxiv.org/abs/2410.18908)

## Voice Omni

- [Generative Expressive Conversational Speech Synthesis](https://arxiv.org/abs/2407.21491)
   - [github.com](https://github.com/walker-hyf/GPT-Talker?tab=readme-ov-file)
   - [mp.weixin.qq.com](https://mp.weixin.qq.com/s/bF4qnMrxcDSbVYHi4jGF_A)
- [Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation](https://arxiv.org/abs/2410.20336)
   - [maohaos2.github.io](https://maohaos2.github.io/TTS-Llama-MoLE-Llama/)
- [GPT-4o System Card](https://arxiv.org/abs/2410.21276)
- **Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant**, `arXiv, 2410.15316`, [arxiv](http://arxiv.org/abs/2410.15316v1), [pdf](http://arxiv.org/pdf/2410.15316v1.pdf), cication: [**-1**](None)

	 *Alan Dao, Dinh Bach Vu, Huy Hoang Ha* · ([ichigo.homebrew](https://ichigo.homebrew.ltd/)) · ([homebrew](https://homebrew.ltd/)) · ([ichigo](https://github.com/homebrewltd/ichigo) - homebrewltd) ![Star](https://img.shields.io/github/stars/homebrewltd/ichigo.svg?style=social&label=Star)
- **Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex
  Capabilities**, `arXiv, 2410.11190`, [arxiv](http://arxiv.org/abs/2410.11190v2), [pdf](http://arxiv.org/pdf/2410.11190v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=14534896134025731094&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhifei Xie, Changqiao Wu* · ([mini-omni2](https://github.com/gpt-omni/mini-omni2) - gpt-omni) ![Star](https://img.shields.io/github/stars/gpt-omni/mini-omni2.svg?style=social&label=Star)

## Duplex

- [OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation](https://arxiv.org/abs/2410.17799)

	 · ([omniflatten.github](https://omniflatten.github.io/))
- [Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents](https://arxiv.org/abs/2409.15594)

	 · ([syncllm.cs.washington](https://syncllm.cs.washington.edu/))

## Evaluation

- [VoiceBench: Benchmarking LLM-Based Voice Assistants](https://arxiv.org/abs/2410.17196)

	 · ([VoiceBench](https://github.com/MatthewCYM/VoiceBench) - MatthewCYM) ![Star](https://img.shields.io/github/stars/MatthewCYM/VoiceBench.svg?style=social&label=Star)
- [Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning](https://arxiv.org/abs/2410.16130)

## Projects

- [KingNish / OpenGPT-4o](https://huggingface.co/spaces/KingNish/OpenGPT-4o/tree/main)
- [**GLM-4-Voice**](https://github.com/THUDM/GLM-4-Voice) - THUDM ![Star](https://img.shields.io/github/stars/THUDM/GLM-4-Voice.svg?style=social&label=Star)
- [homebrewltd / mini-Ichigo-llama3.2-3B-s-instruct](https://huggingface.co/homebrewltd/mini-Ichigo-llama3.2-3B-s-instruct)

## Products

- [voice AI hackathon](https://x.com/hingeloss/status/1851260286415593487)

## Datasets


## Toolkits


## Misc

- [Mini-Omni 2 understands image, audio and text inputs all via end-to-end voice conversations with users](https://x.com/reach_vb/status/1850895844167286859)
- [dotAI 2024 - Neil Zeghidour - Multimodal language models](https://www.youtube.com/watch?v=UgpLM9gNkqs)
- [**s2s_endpoint**](https://huggingface.co/blog/s2s_endpoint) -  🤗