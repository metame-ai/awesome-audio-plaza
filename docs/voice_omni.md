# Voice Omni

- [Voice Omni](#voice-omni) 
  - [Survey](#survey)
  - [Voice Omni](#voice-omni-1)
  - [Duplex](#duplex)
  - [Evaluation](#evaluation)
  - [Projects](#projects)
  - [Products](#products)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Survey

- **WavChat: A Survey of Spoken Dialogue Models**, `arXiv, 2411.13577`, [arxiv](http://arxiv.org/abs/2411.13577v1), [pdf](http://arxiv.org/pdf/2411.13577v1.pdf), cication: [**-1**](None) 

	 *Shengpeng Ji, Yifu Chen, Minghui Fang, ..., Jin Xu, Zhou Zhao*
- [**Awesome-Speech-Language-Model**](https://github.com/ddlBoJack/Awesome-Speech-Language-Model) - ddlBoJack ![Star](https://img.shields.io/github/stars/ddlBoJack/Awesome-Speech-Language-Model.svg?style=social&label=Star) 
- **A Survey on Speech Large Language Models**, `arXiv, 2410.18908`, [arxiv](http://arxiv.org/abs/2410.18908v2), [pdf](http://arxiv.org/pdf/2410.18908v2.pdf), cication: [**-1**](None) 

	 *Jing Peng, Yucheng Wang, Yu Xi, ..., Xizhuo Zhang, Kai Yu*

## Voice Omni

- **Advancing Speech Language Models by Scaling Supervised Fine-Tuning with
  Over 60,000 Hours of Synthetic Speech Dialogue Data**, `arXiv, 2412.01078`, [arxiv](http://arxiv.org/abs/2412.01078v2), [pdf](http://arxiv.org/pdf/2412.01078v2.pdf), cication: [**-1**](None) 

	 *Shuaijiang Zhao, Tingwei Guo, Bajian Xiang, ..., Wei Zou, Xiangang Li* · ([huggingface](https://huggingface.co/spaces/KE-Team/KE-Omni))
- 🌟 [Paper page - Scaling Speech-Text Pre-training with Synthetic Interleaved Data](https://huggingface.co/papers/2411.17607) 
- **SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and 
  Generation**, `arXiv, 2411.18138`, [arxiv](http://arxiv.org/abs/2411.18138v1), [pdf](http://arxiv.org/pdf/2411.18138v1.pdf), cication: [**-1**](None) 

	 *Wenyi Yu, Siyin Wang, Xiaoyu Yang, ..., Yuxuan Wang, Chao Zhang*
- **Internalizing ASR with Implicit Chain of Thought for Efficient 
  Speech-to-Speech Conversational LLM**, `arXiv, 2409.17353`, [arxiv](http://arxiv.org/abs/2409.17353v3), [pdf](http://arxiv.org/pdf/2409.17353v3.pdf), cication: [**-1**](None) 

	 *Robin Shing-Hei Yuen, Timothy Tin-Long Tse, Jian Zhu*
- 🌟 **Building a Taiwanese Mandarin Spoken Language Model: A First Attempt**, `arXiv, 2411.07111`, [arxiv](http://arxiv.org/abs/2411.07111v1), [pdf](http://arxiv.org/pdf/2411.07111v1.pdf), cication: [**-1**](None) 

	 *Chih-Kai Yang, Yu-Kuan Fu, Chen-An Li, ..., Shu-wen Yang, Hung-yi Lee*
- [freddyaboulton / llama-code-editor](https://huggingface.co/spaces/freddyaboulton/llama-code-editor/tree/main)  🤗 
- **Align-SLM: Textless Spoken Language Models with Reinforcement Learning 
  from AI Feedback**, `arXiv, 2411.01834`, [arxiv](http://arxiv.org/abs/2411.01834v1), [pdf](http://arxiv.org/pdf/2411.01834v1.pdf), cication: [**-1**](None) 

	 *Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, ..., Hung-yi Lee, Ivan Bulyko*
- [Introducing hertz-dev, the first open-source base model for conversational audio generation](https://si.inc/hertz-dev/) 

	 · ([x](https://x.com/si_pbc/status/1853184307063660723)) · ([hertz-dev](https://github.com/Standard-Intelligence/hertz-dev?tab=readme-ov-file) - Standard-Intelligence) ![Star](https://img.shields.io/github/stars/Standard-Intelligence/hertz-dev.svg?style=social&label=Star)
- 🌟 **Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model 
  with Frozen LLM**, `arXiv, 2411.00774`, [arxiv](http://arxiv.org/abs/2411.00774v1), [pdf](http://arxiv.org/pdf/2411.00774v1.pdf), cication: [**-1**](None) 

	 *Xiong Wang, Yangze Li, Chaoyou Fu, ..., Xing Sun, Long Ma*

	 · ([freeze-omni.github](https://freeze-omni.github.io/))

	 · ([Freeze-Omni](https://github.com/VITA-MLLM/Freeze-Omni) - VITA-MLLM) ![Star](https://img.shields.io/github/stars/VITA-MLLM/Freeze-Omni.svg?style=social&label=Star)
- **Generative Expressive Conversational Speech Synthesis**, `arXiv, 2407.21491`, [arxiv](http://arxiv.org/abs/2407.21491v2), [pdf](http://arxiv.org/pdf/2407.21491v2.pdf), cication: [**-1**](None) 

	 *Rui Liu, Yifan Hu, Yi Ren, ..., Xiang Yin, Haizhou Li* · ([GPT-Talker](https://github.com/walker-hyf/GPT-Talker?tab=readme-ov-file) - walker-hyf) ![Star](https://img.shields.io/github/stars/walker-hyf/GPT-Talker.svg?style=social&label=Star) · ([mp.weixin.qq](https://mp.weixin.qq.com/s/bF4qnMrxcDSbVYHi4jGF_A))
- **Get Large Language Models Ready to Speak: A Late-fusion Approach for 
  Speech Generation**, `arXiv, 2410.20336`, [arxiv](http://arxiv.org/abs/2410.20336v1), [pdf](http://arxiv.org/pdf/2410.20336v1.pdf), cication: [**-1**](None)

	 *Maohao Shen, Shun Zhang, Jilong Wu, ..., Mike Seltzer, Qing He* · ([maohaos2.github](https://maohaos2.github.io/TTS-Llama-MoLE-Llama/))
- **GPT-4o System Card**, `arXiv, 2410.21276`, [arxiv](http://arxiv.org/abs/2410.21276v1), [pdf](http://arxiv.org/pdf/2410.21276v1.pdf), cication: [**-1**](None) 

	 *OpenAI, :, Aaron Hurst, ..., Yunxing Dai, Yury Malkov*
- **Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant**, `arXiv, 2410.15316`, [arxiv](http://arxiv.org/abs/2410.15316v1), [pdf](http://arxiv.org/pdf/2410.15316v1.pdf), cication: [**-1**](None) 

	 *Alan Dao, Dinh Bach Vu, Huy Hoang Ha* · ([ichigo.homebrew](https://ichigo.homebrew.ltd/)) · ([homebrew](https://homebrew.ltd/)) · ([ichigo](https://github.com/homebrewltd/ichigo) - homebrewltd) ![Star](https://img.shields.io/github/stars/homebrewltd/ichigo.svg?style=social&label=Star)
- 🌟 **Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex 
  Capabilities**, `arXiv, 2410.11190`, [arxiv](http://arxiv.org/abs/2410.11190v2), [pdf](http://arxiv.org/pdf/2410.11190v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=14534896134025731094&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhifei Xie, Changqiao Wu* · ([mini-omni2](https://github.com/gpt-omni/mini-omni2) - gpt-omni) ![Star](https://img.shields.io/github/stars/gpt-omni/mini-omni2.svg?style=social&label=Star)

## Duplex

- 🌟 **OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation**, `arXiv, 2410.17799`, [arxiv](http://arxiv.org/abs/2410.17799v1), [pdf](http://arxiv.org/pdf/2410.17799v1.pdf), cication: [**-1**](None) 

	 *Qinglin Zhang, Luyao Cheng, Chong Deng, ..., Hai Yu, Chaohong Tan*

	 · ([omniflatten.github](https://omniflatten.github.io/))
- **Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue 
  Agents**, `arXiv, 2409.15594`, [arxiv](http://arxiv.org/abs/2409.15594v1), [pdf](http://arxiv.org/pdf/2409.15594v1.pdf), cication: [**-1**](None)

	 *Bandhav Veluri, Benjamin N Peloquin, Bokai Yu, ..., Hongyu Gong, Shyamnath Gollakota*

	 · ([syncllm.cs.washington](https://syncllm.cs.washington.edu/))

## Evaluation

- **VoiceBench: Benchmarking LLM-Based Voice Assistants**, `arXiv, 2410.17196`, [arxiv](http://arxiv.org/abs/2410.17196v1), [pdf](http://arxiv.org/pdf/2410.17196v1.pdf), cication: [**-1**](None) 

	 *Yiming Chen, Xianghu Yue, Chen Zhang, ..., Robby T. Tan, Haizhou Li*

	 · ([VoiceBench](https://github.com/MatthewCYM/VoiceBench) - MatthewCYM) ![Star](https://img.shields.io/github/stars/MatthewCYM/VoiceBench.svg?style=social&label=Star)
- **Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with 
  Multi-Task Assessment and Stepwise Audio Reasoning**, `arXiv, 2410.16130`, [arxiv](http://arxiv.org/abs/2410.16130v1), [pdf](http://arxiv.org/pdf/2410.16130v1.pdf), cication: [**-1**](None)

	 *Chun-Yi Kuan, Hung-yi Lee*

## Projects

- [**AnyModal**](https://github.com/ritabratamaiti/AnyModal) - ritabratamaiti ![Star](https://img.shields.io/github/stars/ritabratamaiti/AnyModal.svg?style=social&label=Star) 

	 *A Flexible Multimodal Language Model Framework*
- [**VideoChat**](https://github.com/Henry-23/VideoChat) - Henry-23 ![Star](https://img.shields.io/github/stars/Henry-23/VideoChat.svg?style=social&label=Star) 
- [**ultravox**](https://github.com/fixie-ai/ultravox) - fixie-ai ![Star](https://img.shields.io/github/stars/fixie-ai/ultravox.svg?style=social&label=Star) 

	 · ([demo.ultravox](https://demo.ultravox.ai/)) · ([huggingface](https://huggingface.co/fixie-ai/))
- [**WavChat**](https://github.com/jishengpeng/WavChat) - jishengpeng ![Star](https://img.shields.io/github/stars/jishengpeng/WavChat.svg?style=social&label=Star) 

	 *A Survey of Spoken Dialogue Models*
- [**gradio-groq-basics**](https://github.com/bklieger-groq/gradio-groq-basics/blob/main/calorie-tracker/README.md) - bklieger-groq ![Star](https://img.shields.io/github/stars/bklieger-groq/gradio-groq-basics.svg?style=social&label=Star) 

	 · ([𝕏](https://x.com/BenjaminKlieger/status/1854266346290434501))
- [Fish Agent V0.1 3B is a groundbreaking Voice-to-Voice model capable of capturing and generating environmental audio information with unprecedented accuracy.](https://huggingface.co/fishaudio/fish-agent-v0.1-3b)  🤗 
- [KingNish / OpenGPT-4o](https://huggingface.co/spaces/KingNish/OpenGPT-4o/tree/main)  🤗 
- [**GLM-4-Voice**](https://github.com/THUDM/GLM-4-Voice) - THUDM ![Star](https://img.shields.io/github/stars/THUDM/GLM-4-Voice.svg?style=social&label=Star) 
- [homebrewltd / mini-Ichigo-llama3.2-3B-s-instruct](https://huggingface.co/homebrewltd/mini-Ichigo-llama3.2-3B-s-instruct)  🤗 

## Products

- [voice AI hackathon](https://x.com/hingeloss/status/1851260286415593487)  𝕏 

## Datasets


## Toolkits


## Misc

- [**TEN-Agent**](https://github.com/TEN-framework/TEN-Agent) - TEN-framework ![Star](https://img.shields.io/github/stars/TEN-framework/TEN-Agent.svg?style=social&label=Star) 
- [Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming](https://www.semanticscholar.org/paper/Mini-Omni%3A-Language-Models-Can-Hear%2C-Talk-While-in-Xie-Wu/8625ab06f76caf36ab138bac20a3116ba5b298e6) 
- [Talk to AI with natural speech detection](https://x.com/BenjaminKlieger/status/1853899938561917355)  𝕏 
- [chatgpt voice demo with mini-omni 2 (multimodal)](https://x.com/freddy_alfonso_/status/1852071457406259553)  𝕏 
- [Mini-Omni 2 understands image, audio and text inputs all via end-to-end voice conversations with users](https://x.com/reach_vb/status/1850895844167286859)  𝕏 
- :clapper: [dotAI 2024 - Neil Zeghidour - Multimodal language models](https://www.youtube.com/watch?v=UgpLM9gNkqs) 
- [**s2s_endpoint**](https://huggingface.co/blog/s2s_endpoint) -  🤗 