# Voice Omni

- [Voice Omni](#voice-omni) 
  - [Survey](#survey)
  - [Voice Omni](#voice-omni-1)
  - [Duplex](#duplex)
  - [Evaluation](#evaluation)
  - [Projects](#projects)
  - [Products](#products)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Survey

- **A Survey on Speech Large Language Models**, `arXiv, 2410.18908`, [arxiv](http://arxiv.org/abs/2410.18908v2), [pdf](http://arxiv.org/pdf/2410.18908v2.pdf), cication: [**-1**](None) 

	 *Jing Peng, Yucheng Wang, Yu Xi, ..., Xizhuo Zhang, Kai Yu*

## Voice Omni

- [Introducing hertz-dev, the first open-source base model for conversational audio generation](https://si.inc/hertz-dev/) 

	 路 ([x](https://x.com/si_pbc/status/1853184307063660723)) 路 ([hertz-dev](https://github.com/Standard-Intelligence/hertz-dev?tab=readme-ov-file) - Standard-Intelligence) ![Star](https://img.shields.io/github/stars/Standard-Intelligence/hertz-dev.svg?style=social&label=Star)
- [Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM](https://arxiv.org/abs/2411.00774)

	 路 ([freeze-omni.github](https://freeze-omni.github.io/))
- **Generative Expressive Conversational Speech Synthesis**, `arXiv, 2407.21491`, [arxiv](http://arxiv.org/abs/2407.21491v2), [pdf](http://arxiv.org/pdf/2407.21491v2.pdf), cication: [**-1**](None) 

	 *Rui Liu, Yifan Hu, Yi Ren, ..., Xiang Yin, Haizhou Li* 路 ([GPT-Talker](https://github.com/walker-hyf/GPT-Talker?tab=readme-ov-file) - walker-hyf) ![Star](https://img.shields.io/github/stars/walker-hyf/GPT-Talker.svg?style=social&label=Star) 路 ([mp.weixin.qq](https://mp.weixin.qq.com/s/bF4qnMrxcDSbVYHi4jGF_A))
- **Get Large Language Models Ready to Speak: A Late-fusion Approach for 
  Speech Generation**, `arXiv, 2410.20336`, [arxiv](http://arxiv.org/abs/2410.20336v1), [pdf](http://arxiv.org/pdf/2410.20336v1.pdf), cication: [**-1**](None)

	 *Maohao Shen, Shun Zhang, Jilong Wu, ..., Mike Seltzer, Qing He* 路 ([maohaos2.github](https://maohaos2.github.io/TTS-Llama-MoLE-Llama/))
- **GPT-4o System Card**, `arXiv, 2410.21276`, [arxiv](http://arxiv.org/abs/2410.21276v1), [pdf](http://arxiv.org/pdf/2410.21276v1.pdf), cication: [**-1**](None) 

	 *OpenAI, :, Aaron Hurst, ..., Yunxing Dai, Yury Malkov*
- **Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant**, `arXiv, 2410.15316`, [arxiv](http://arxiv.org/abs/2410.15316v1), [pdf](http://arxiv.org/pdf/2410.15316v1.pdf), cication: [**-1**](None) 

	 *Alan Dao, Dinh Bach Vu, Huy Hoang Ha* 路 ([ichigo.homebrew](https://ichigo.homebrew.ltd/)) 路 ([homebrew](https://homebrew.ltd/)) 路 ([ichigo](https://github.com/homebrewltd/ichigo) - homebrewltd) ![Star](https://img.shields.io/github/stars/homebrewltd/ichigo.svg?style=social&label=Star)
- **Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex 
  Capabilities**, `arXiv, 2410.11190`, [arxiv](http://arxiv.org/abs/2410.11190v2), [pdf](http://arxiv.org/pdf/2410.11190v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=14534896134025731094&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhifei Xie, Changqiao Wu* 路 ([mini-omni2](https://github.com/gpt-omni/mini-omni2) - gpt-omni) ![Star](https://img.shields.io/github/stars/gpt-omni/mini-omni2.svg?style=social&label=Star)

## Duplex

- **OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation**, `arXiv, 2410.17799`, [arxiv](http://arxiv.org/abs/2410.17799v1), [pdf](http://arxiv.org/pdf/2410.17799v1.pdf), cication: [**-1**](None) 

	 *Qinglin Zhang, Luyao Cheng, Chong Deng, ..., Hai Yu, Chaohong Tan*

	 路 ([omniflatten.github](https://omniflatten.github.io/))
- **Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue 
  Agents**, `arXiv, 2409.15594`, [arxiv](http://arxiv.org/abs/2409.15594v1), [pdf](http://arxiv.org/pdf/2409.15594v1.pdf), cication: [**-1**](None)

	 *Bandhav Veluri, Benjamin N Peloquin, Bokai Yu, ..., Hongyu Gong, Shyamnath Gollakota*

	 路 ([syncllm.cs.washington](https://syncllm.cs.washington.edu/))

## Evaluation

- **VoiceBench: Benchmarking LLM-Based Voice Assistants**, `arXiv, 2410.17196`, [arxiv](http://arxiv.org/abs/2410.17196v1), [pdf](http://arxiv.org/pdf/2410.17196v1.pdf), cication: [**-1**](None) 

	 *Yiming Chen, Xianghu Yue, Chen Zhang, ..., Robby T. Tan, Haizhou Li*

	 路 ([VoiceBench](https://github.com/MatthewCYM/VoiceBench) - MatthewCYM) ![Star](https://img.shields.io/github/stars/MatthewCYM/VoiceBench.svg?style=social&label=Star)
- **Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with 
  Multi-Task Assessment and Stepwise Audio Reasoning**, `arXiv, 2410.16130`, [arxiv](http://arxiv.org/abs/2410.16130v1), [pdf](http://arxiv.org/pdf/2410.16130v1.pdf), cication: [**-1**](None)

	 *Chun-Yi Kuan, Hung-yi Lee*

## Projects

- [Fish Agent V0.1 3B is a groundbreaking Voice-to-Voice model capable of capturing and generating environmental audio information with unprecedented accuracy.](https://huggingface.co/fishaudio/fish-agent-v0.1-3b)   
- [KingNish / OpenGPT-4o](https://huggingface.co/spaces/KingNish/OpenGPT-4o/tree/main)   
- [**GLM-4-Voice**](https://github.com/THUDM/GLM-4-Voice) - THUDM ![Star](https://img.shields.io/github/stars/THUDM/GLM-4-Voice.svg?style=social&label=Star) 
- [homebrewltd / mini-Ichigo-llama3.2-3B-s-instruct](https://huggingface.co/homebrewltd/mini-Ichigo-llama3.2-3B-s-instruct)   

## Products

- [voice AI hackathon](https://x.com/hingeloss/status/1851260286415593487)   

## Datasets


## Toolkits


## Misc

- [chatgpt voice demo with mini-omni 2 (multimodal)](https://x.com/freddy_alfonso_/status/1852071457406259553)   
- [Mini-Omni 2 understands image, audio and text inputs all via end-to-end voice conversations with users](https://x.com/reach_vb/status/1850895844167286859)   
- :clapper: [dotAI 2024 - Neil Zeghidour - Multimodal language models](https://www.youtube.com/watch?v=UgpLM9gNkqs) 
- [**s2s_endpoint**](https://huggingface.co/blog/s2s_endpoint) -   