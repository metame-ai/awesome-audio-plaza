# Awesome Audio Gallery

- [Awesome Audio Gallery](#awesome-audio-gallery)
  - [Courses and Tutorials](#courses-and-tutorials)
    - [DLHLP 2020 Spring](#dlhlp-2020-spring)
    - [Large Audio Model](#large-audio-model)
  - [Speech Translation](#speech-translation)
  - [Toolkits](#toolkits)
  - [Dataset](#dataset)
    - [TTS](#tts)
  - [Audio Techs](#audio-techs)


## Courses and Tutorials

### DLHLP 2020 Spring
- [DLHLP 2020 Spring](https://speech.ee.ntu.edu.tw/~hylee/dlhlp/2020-spring.php)
- [[DLHLP 2020] æå®æ¯…è€å¸ˆ2020æ˜¥è¯¾ç¨‹-è¯­éŸ³è¯†åˆ«-è¯­éŸ³åˆæˆ-è¯­éŸ³åˆ†ç¦»\_å“”å“©å“”å“©\_bilibili](https://www.bilibili.com/video/BV1hZ4y1w7j1/?spm_id_from=333.788.top_right_bar_window_custom_collection.content.click&vd_source=1453a06a1e0b377f5c40946333b4423a)
- [[DLHLP 2020] Vocoder (ç”±åŠ©æ•™è¨±åšç«£åŒå­¸è¬›æˆ)\_å“”å“©å“”å“©\_bilibili](https://www.bilibili.com/video/BV1hZ4y1w7j1?p=11&vd_source=1453a06a1e0b377f5c40946333b4423a)
- TTS Intro: [[DLHLP 2020] Speech Synthesis (1/2) - Tacotron - YouTube](https://www.youtube.com/watch?v=DMxKeHW8KdM&ab_channel=Hung-yiLee)

### Large Audio Model
- [ã€æ©Ÿå™¨å­¸ç¿’2023ã€‘èªéŸ³åŸºçŸ³æ¨¡å‹ (åŠ©æ•™å¼µå‡±ç‚ºè¬›æˆ) (1/2) - YouTube](https://www.youtube.com/watch?v=m7Be7ppR6q0&ab_channel=Hung-yiLee)
- [ã€æ©Ÿå™¨å­¸ç¿’2023ã€‘èªéŸ³åŸºçŸ³æ¨¡å‹ (åŠ©æ•™å¼µå‡±ç‚ºè¬›æˆ) (2/2) - YouTube](https://www.youtube.com/watch?v=HTAq-CPrU5s&ab_channel=Hung-yiLee)
- [https://speech.ee.ntu.edu.tw/\~hylee/ml/ml2023-course-data/å¼µå‡±çˆ²-x-æ©Ÿå™¨å­¸ç¿’-x-èªéŸ³åŸºçŸ³æ¨¡å‹.pdf](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2023-course-data/%E5%BC%B5%E5%87%B1%E7%88%B2-x-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-x-%E8%AA%9E%E9%9F%B3%E5%9F%BA%E7%9F%B3%E6%A8%A1%E5%9E%8B.pdf)

## Speech Translation

- **PolyVoice: Language Models for Speech to Speech Translation**, `arXiv, 2306.02982`, [arxiv](http://arxiv.org/abs/2306.02982v2), [pdf](http://arxiv.org/pdf/2306.02982v2.pdf), cication: [**-1**](None)

	 *Qianqian Dong, Zhiying Huang, Qiao Tian, Chen Xu, Tom Ko, Yunlong Zhao, Siyuan Feng, Tang Li, Kexin Wang, Xuxin Cheng* Â· ([speechtranslation.github](https://speechtranslation.github.io/polyvoice/))
- [**fairseq**](https://github.com/facebookresearch/fairseq/tree/ust/examples/hokkien) - facebookresearch ![Star](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social&label=Star)

## Toolkits

- [**deepfilternet**](https://github.com/rikorose/deepfilternet) - rikorose ![Star](https://img.shields.io/github/stars/rikorose/deepfilternet.svg?style=social&label=Star)

	 *Noise supression using deep filtering*
- [**CharsiuG2P**](https://github.com/lingjzhu/CharsiuG2P) - lingjzhu ![Star](https://img.shields.io/github/stars/lingjzhu/CharsiuG2P.svg?style=social&label=Star)

	 *Multilingual G2P in 100 languages*
- [(Inverse) Text Normalization â€” NVIDIA NeMo](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/text_normalization/intro.html)
- [**audio-preprocess**](https://github.com/fishaudio/audio-preprocess) - fishaudio ![Star](https://img.shields.io/github/stars/fishaudio/audio-preprocess.svg?style=social&label=Star)

	 *Preprocess Audio for training*
- [**pyloudnorm**](https://github.com/csteinmetz1/pyloudnorm) - csteinmetz1 ![Star](https://img.shields.io/github/stars/csteinmetz1/pyloudnorm.svg?style=social&label=Star)

	 *Flexible audio loudness meter in Python with implementation of ITU-R BS.1770-4 loudness algorithm*
- [**ultimatevocalremovergui**](https://github.com/Anjok07/ultimatevocalremovergui) - Anjok07 ![Star](https://img.shields.io/github/stars/Anjok07/ultimatevocalremovergui.svg?style=social&label=Star)

	 *GUI for a Vocal Remover that uses Deep Neural Networks.*
- **Amphion: An Open-Source Audio, Music and Speech Generation Toolkit**, `arXiv, 2312.09911`, [arxiv](http://arxiv.org/abs/2312.09911v1), [pdf](http://arxiv.org/pdf/2312.09911v1.pdf), cication: [**-1**](None)

	 *Xueyao Zhang, Liumeng Xue, Yuancheng Wang, Yicheng Gu, Xi Chen, Zihao Fang, Haopeng Chen, Lexiao Zou, Chaoren Wang, Jun Han* Â· ([huggingface](https://huggingface.co/amphion)) Â· ([Amphion](https://github.com/open-mmlab/Amphion/tree/main) - open-mmlab) ![Star](https://img.shields.io/github/stars/open-mmlab/Amphion.svg?style=social&label=Star)
- [**resemble-enhance**](https://github.com/resemble-ai/resemble-enhance) - resemble-ai ![Star](https://img.shields.io/github/stars/resemble-ai/resemble-enhance.svg?style=social&label=Star)

	 *AI powered speech denoising and enhancement*
- [**awesome-python**](https://github.com/vinta/awesome-python#audio) - vinta ![Star](https://img.shields.io/github/stars/vinta/awesome-python.svg?style=social&label=Star)

	 *A curated list of awesome Python frameworks, libraries, software and resources*
- [**pyannote-audio**](https://github.com/pyannote/pyannote-audio) - pyannote ![Star](https://img.shields.io/github/stars/pyannote/pyannote-audio.svg?style=social&label=Star)

	 *Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding*
- [**audiocraft**](https://github.com/facebookresearch/audiocraft) - facebookresearch ![Star](https://img.shields.io/github/stars/facebookresearch/audiocraft.svg?style=social&label=Star)

	 *Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.*
- [**audio-slicer**](https://github.com/openvpi/audio-slicer) - openvpi ![Star](https://img.shields.io/github/stars/openvpi/audio-slicer.svg?style=social&label=Star)

	 *Python script that slices audio with silence detection*
- [**autocut**](https://github.com/mli/autocut/blob/main/autocut/transcribe.py) - mli ![Star](https://img.shields.io/github/stars/mli/autocut.svg?style=social&label=Star)

## Dataset

- [**common_voice_16_0**](https://huggingface.co/datasets/mozilla-foundation/common_voice_16_0) - mozilla-foundation ğŸ¤—
- [**GigaSpeech**](https://github.com/SpeechColab/GigaSpeech) - SpeechColab ![Star](https://img.shields.io/github/stars/SpeechColab/GigaSpeech.svg?style=social&label=Star)

	 *Large, modern dataset for speech recognition*
![](media/Pasted%20image%2020230726185138.png)
- [ä¸­è‹±æ–‡æ•°æ®æ”¶é›†](https://yqli.tech/page/data.html)

### TTS
- **LibriTTS-R: A Restored Multi-Speaker Text-to-Speech Corpus**, `arXiv, 2305.18802`, [arxiv](http://arxiv.org/abs/2305.18802v1), [pdf](http://arxiv.org/pdf/2305.18802v1.pdf), cication: [**-1**](None)

	 *Yuma Koizumi, Heiga Zen, Shigeki Karita, Yifan Ding, Kohei Yatabe, Nobuyuki Morioka, Michiel Bacchiani, Yu Zhang, Wei Han, Ankur Bapna* Â· ([openslr](http://www.openslr.org/141/)) Â· ([google.github](https://google.github.io/df-conformer/librittsr/))
- **MLS: A Large-Scale Multilingual Dataset for Speech Research**, `arXiv, 2012.03411`, [arxiv](http://arxiv.org/abs/2012.03411v2), [pdf](http://arxiv.org/pdf/2012.03411v2.pdf), cication: [**-1**](None)

	 *Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, Ronan Collobert* Â· ([openslr](http://www.openslr.org/94/))
	- Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. 
	- segment the audio files into 10-20 second segments 
- **LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech**, `arXiv, 1904.02882`, [arxiv](http://arxiv.org/abs/1904.02882v1), [pdf](http://arxiv.org/pdf/1904.02882v1.pdf), cication: [**-1**](None)

	 *Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J. Weiss, Ye Jia, Zhifeng Chen, Yonghui Wu*
- **Hi-Fi Multi-Speaker English TTS Dataset**, `arXiv, 2104.01497`, [arxiv](http://arxiv.org/abs/2104.01497v3), [pdf](http://arxiv.org/pdf/2104.01497v3.pdf), cication: [**-1**](None)

	 *Evelina Bakhturina, Vitaly Lavrukhin, Boris Ginsburg, Yang Zhang* Â· ([openslr](https://www.openslr.org/109/))

## Audio Techs
- **EfficientSpeech: An On-Device Text to Speech Model**, `arXiv, 2305.13905`, [arxiv](http://arxiv.org/abs/2305.13905v1), [pdf](http://arxiv.org/pdf/2305.13905v1.pdf), cication: [**-1**](None)

	 *Rowel Atienza*
- **Visual-Aware Text-to-Speech**, `arXiv, 2306.12020`, [arxiv](http://arxiv.org/abs/2306.12020v1), [pdf](http://arxiv.org/pdf/2306.12020v1.pdf), cication: [**-1**](None)

	 *Mohan Zhou, Yalong Bai, Wei Zhang, Ting Yao, Tiejun Zhao, Tao Mei*
- **Proactive Detection of Voice Cloning with Localized Watermarking**, `arXiv, 2401.17264`, [arxiv](http://arxiv.org/abs/2401.17264v1), [pdf](http://arxiv.org/pdf/2401.17264v1.pdf), cication: [**-1**](None)

	 *Robin San Roman, Pierre Fernandez, Alexandre DÃ©fossez, Teddy Furon, Tuan Tran, Hady Elsahar*
- **FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for
  Acoustic Echo Cancellation**, `arXiv, 2401.04283`, [arxiv](http://arxiv.org/abs/2401.04283v1), [pdf](http://arxiv.org/pdf/2401.04283v1.pdf), cication: [**-1**](None)

	 *Yang Liu, Li Wan, Yun Li, Yiteng Huang, Ming Sun, James Luan, Yangyang Shi, Xin Lei*
- [**AudioSep**](https://github.com/Audio-AGI/AudioSep) - Audio-AGI ![Star](https://img.shields.io/github/stars/Audio-AGI/AudioSep.svg?style=social&label=Star)

	 *Official implementation of "Separate Anything You Describe"*
- **AudioSR: Versatile Audio Super-resolution at Scale**, `arXiv, 2309.07314`, [arxiv](http://arxiv.org/abs/2309.07314v1), [pdf](http://arxiv.org/pdf/2309.07314v1.pdf), cication: [**-1**](None)

	 *Haohe Liu, Ke Chen, Qiao Tian, Wenwu Wang, Mark D. Plumbley*